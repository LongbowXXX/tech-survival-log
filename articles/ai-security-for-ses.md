---
title: "【資料公開】SESエンジニアが「現場」で生成AIを安全に使い倒すためのセキュリティ生存戦略"
emoji: "🛡️"
type: "idea" # 考察や知見の共有なのでideaに設定
topics: ["ses", "security", "ai", "generative-ai", "career"]
published: false
---

最近、生成 AI のセキュリティに関する記事やスライドをよく見かけます。
しかし、それらを読んでいて SES エンジニアが日常的に直面する **「自社のルール」と「現場（常駐先）のルール」の狭間** についての視点が足りないと感じました。

一般的な正論だけでは片付かない、SES ならではの現実を踏まえたセキュリティの指針が必要だと感じ、社内研修などで使えるようなスライドを作成しました。

## 作成したスライド

@[speakerdeck](5b51d5ea11c5406984d68975f70dc86a)

## なぜこの資料を作ったのか

世の中の「AI セキュリティガイドライン」の多くは、自社開発企業や、単一の組織内での運用を前提としています。
しかし、SES エンジニアの現実はもう少し複雑です。

この資料では、そういった **「SES 特有の事情」** を含めた上で、エンジニアが自分の身と現場を守るための最低限のリテラシーをまとめています。

## スライドの要点

### 1. 「現場のルール」が絶対、なければ「自社ルール」がベースライン

SES エンジニアにとって、指揮命令系統は非常に重要です。
資料では、 **「現場（常駐先）のルールが最優先」** であることを大前提としつつ、明確な規定がない場合のベースラインとして今回の知識を使うよう定義しました。
「判断に迷ったら現場の指揮命令者に確認する」。この当たり前のプロセスこそが、最大の防御壁です。

### 2. Shadow AI と サプライチェーン攻撃

単なる「情報漏洩」だけでなく、エンジニアがついやってしまいがちな具体的なリスクを取り上げました。

- **Shadow AI:** 許可されていない個人の無料アカウント等を勝手に業務利用すること。
- **パッケージの幻覚:** AI が提案した「実在しそうなライブラリ名」をそのまま `npm install` したら、実は攻撃者が仕込んだマルウェアだった、というサプライチェーン攻撃の手口。

特に後者は、C++などの組み込み時代にはあまり意識しなかった、モダン開発 ×AI 時代特有の恐怖です。

### 3. 「GitHub Copilot Business/Enterprise」を選ぶ理由

なぜ現場では個人版（Individual）ではなく[ビジネス版（Business/Enterprise）が推奨](https://resources.github.com/learn/pathways/copilot/essentials/establishing-trust-in-using-github-copilot/)されるのか。
その最大の理由は **「データ保護（学習に利用されないこと）」** に尽きます。
クライアントに安心してもらうための説明材料としても、この違いを理解しておくことは生存戦略上必須です。

## セキュリティは「ブレーキ」ではない

昔の組み込み開発でメモリ安全性を意識したように、今の時代は「AI 安全性」を意識する必要があります。

セキュリティルールは開発を遅らせるための「足かせ（ブレーキ）」ではありません。
フルスピードで事故らずに開発するための「ガードレール」です。

この資料が、SES エンジニアの方々の助けになれば幸いです。

---

## 🛠️ この記事で活用した AI スタック

このブログでは「AI 時代を生き抜く生存戦略」の実践として、以下の AI ツールをパートナーとして活用しています。

- **GitHub Copilot / Google Antigravity:** Zenn 連携リポジトリ内での記事生成、PR 作成、作業プロセスの簡略化・自動化
- **Gemini Advanced:** 記事ドラフトの推敲、表現の壁打ち、スライド生成
- **NotebookLM:** 関連ドキュメントの読み込み、情報の整理

※AI はあくまで支援ツールとして利用しており、最終的なファクトチェックと記事の確認は人間が行います。
